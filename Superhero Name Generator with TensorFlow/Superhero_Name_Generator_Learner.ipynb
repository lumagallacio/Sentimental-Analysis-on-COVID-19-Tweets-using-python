{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Superhero_Name_Generator_Learner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lumagallacio/python-projects/blob/main/Superhero%20Name%20Generator%20with%20TensorFlow/Superhero_Name_Generator_Learner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21XXWP7Fpt2L"
      },
      "source": [
        "# Superhero (and Supervillain) Name Generator\n",
        "\n",
        "We are going to create a model that will predict the character for a given sequence. We will give for our trainned model a seed input, this can be a single character or a sequence. So the model will generate the next character. It will predict the next character in that sequence. This character is added to the seed input to create a new input, wich is then used again to generate the next character and soon.\n",
        "\n",
        "This project uses TensorFlow and Google Colab. We will understand how use TensorFlow framework to start performing natural language processing tasks like text classification, text generation.\n",
        "\n",
        "---\n",
        "\n",
        "[Superhero Names Dataset](https://github.com/am1tyadav/superhero)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6P0NU5Cpt2R"
      },
      "source": [
        "## Task 2\n",
        "\n",
        "1. Import the data\n",
        "2. Create a tokenizer\n",
        "3. Char to index and Index to char dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srULhalZpt2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d8da9ff-72d7-4757-c6a6-fdaeff36adfe"
      },
      "source": [
        "!git clone https://github.com/am1tyadav/superhero"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'superhero' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq4CLmsLpt2P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ee0a100e-f031-405d-fb79-9cd0ecb0cf25"
      },
      "source": [
        "with open('/content/superhero/superheroes.txt', 'r') as f:\n",
        "  data = f.read()\n",
        "\n",
        "data[:100] #print firts 10 character\n",
        "# \\n is a new line character\n",
        "# \\t is a tab and indicates the end of the name"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'jumpa\\t\\ndoctor fate\\t\\nstarlight\\t\\nisildur\\t\\nlasher\\t\\nvarvara\\t\\nthe target\\t\\naxel\\t\\nbattra\\t\\nchangeling\\t\\npyrrh'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0s0pvpM-0DR"
      },
      "source": [
        "for train our model with this data, we cannot feed the characters, we have to tokennize them. What means that we have to create a numeric representation for our characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqhtLuAHpt2R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba687f5-1581-440d-b4ed-95776ed48e4b"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_6W6I9J_mGJ"
      },
      "source": [
        "we need specify filters because we want to keep the tab character in our examples. Bur we are filtering all the other symbols that we don't want to use in our vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95Lo1Yqzpt2T"
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~',\n",
        "    split='\\n',\n",
        ")"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpyDQFdxA02S"
      },
      "source": [
        "after fit our data, it's able to convert sequence of characters to sequence of number. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYfC4sj2pt2V"
      },
      "source": [
        "tokenizer.fit_on_texts(data)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CMOxvxWBgbW"
      },
      "source": [
        "two dictionary. Firts transform characters to indices, it's important because neural network model does not understand characters but it does understand numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO4-dPM6pt2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45476f97-f729-4818-cab1-a1287d6f7293"
      },
      "source": [
        "char_to_index = tokenizer.word_index #characters to indices\n",
        "\n",
        "index_to_char = dict((v,k) for k,v in char_to_index.items()) #indices to characters\n",
        "\n",
        "print(index_to_char)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: '\\t', 2: 'a', 3: 'e', 4: 'r', 5: 'o', 6: 'n', 7: 'i', 8: ' ', 9: 't', 10: 's', 11: 'l', 12: 'm', 13: 'h', 14: 'd', 15: 'c', 16: 'u', 17: 'g', 18: 'k', 19: 'b', 20: 'p', 21: 'y', 22: 'w', 23: 'f', 24: 'v', 25: 'j', 26: 'z', 27: 'x', 28: 'q'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMwtIw_Bpt2Z"
      },
      "source": [
        "## Task 3\n",
        "\n",
        "1. Converting between names and sequences\n",
        "\n",
        "the predictions of our model are going to be sequences of number, so we need to convert again, using the dictionaries that we created in the previous task, to names. So we want to see our predictions converted to names."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRsAxWcrxuFu"
      },
      "source": [
        "Let's take a look at all the names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7iQLIXzpt2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af4e3355-315d-493d-f119-094d08664c85"
      },
      "source": [
        "names = data.splitlines() #returns a list with all the lines in string using \\n \r\n",
        "names[:10]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jumpa\\t',\n",
              " 'doctor fate\\t',\n",
              " 'starlight\\t',\n",
              " 'isildur\\t',\n",
              " 'lasher\\t',\n",
              " 'varvara\\t',\n",
              " 'the target\\t',\n",
              " 'axel\\t',\n",
              " 'battra\\t',\n",
              " 'changeling\\t']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1r1Je3syTFa"
      },
      "source": [
        "to convert char to number we just need to use the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_-TTfqipt2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd6511a-d922-458c-b536-2cb4d875d482"
      },
      "source": [
        "tokenizer.texts_to_sequences(names[0]) # just pass \"jumpa\" name"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[25], [16], [12], [20], [2], [1]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfzCUDaZzur5"
      },
      "source": [
        "we will create a function to do this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6IsKH1Upt2e"
      },
      "source": [
        "def name_to_seq(name):\r\n",
        "  return [tokenizer.texts_to_sequences(c)[0][0] for c in name]"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuLUiMP3pt2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db0cf593-6144-47c8-eaa0-ce383257bc14"
      },
      "source": [
        "name_to_seq(names[0])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[25, 16, 12, 20, 2, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yTamn6G1wC0"
      },
      "source": [
        "we need to do the oposite\r\n",
        "\r\n",
        "0 is not defined. We look ate the caracter value associated with the index anf then joined to create a name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFUYhimKpt2h"
      },
      "source": [
        "def seq_to_name(seq):\r\n",
        "  return ''.join([index_to_char[i] for i in seq if i !=0]) "
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROhCqmhLpt2k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9ba3da9c-2283-4228-e920-33ea17fa4b77"
      },
      "source": [
        "seq_to_name(name_to_seq(names[0]))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'jumpa\\t'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqUslVMA8gFj"
      },
      "source": [
        ""
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCbAzsNjpt2m"
      },
      "source": [
        "## Task 4\n",
        "\n",
        "1. Creating sequences\n",
        "2. Padding all sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-hnackJ0tCQ"
      },
      "source": [
        "we will create sequences (of numbers). these sequences are essentially all the examples from all the names that we have in our dataset. So let's create a list of sequences.\r\n",
        "\r\n",
        "For example, the name \"jumpa\\t\", we can split that to J and U where J will be the input example and U is going to be the label. We are asking to the model that, hey if you see a sequence with just J in it, then predict U. But the sequences can be longer, but at least they need to be two characters long. So we're starting with two, and then will be three in the next iteration, so our example will  become JUM and will be added to sequences. And then we will have JUMP and than JUMPA, JUMPA\\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpHJN2s0BP5V",
        "outputId": "a91a4378-8dc9-41a9-b3e6-6f34b2b3053b"
      },
      "source": [
        "sequence1=[]\r\n",
        "seq = name_to_seq(names[0])\r\n",
        "if len(seq)>=2: #each example with at least two characters \r\n",
        "  sequence1 += [seq[:i] for i in range(2, len(seq)+1)]\r\n",
        "sequence1"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[25, 16],\n",
              " [25, 16, 12],\n",
              " [25, 16, 12, 20],\n",
              " [25, 16, 12, 20, 2],\n",
              " [25, 16, 12, 20, 2, 1]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zstNn-0dpt2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cc6b7c0-87d2-46a2-8738-a5c95b8fbf02"
      },
      "source": [
        "sequences = []\r\n",
        "\r\n",
        "for name in names:\r\n",
        "  seq = name_to_seq(name)\r\n",
        "  if len(seq)>=2: #each example with at least two characters \r\n",
        "    sequences += [seq[:i] for i in range(2, len(seq)+1)]\r\n",
        "sequences[:10]  "
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[25, 16],\n",
              " [25, 16, 12],\n",
              " [25, 16, 12, 20],\n",
              " [25, 16, 12, 20, 2],\n",
              " [25, 16, 12, 20, 2, 1],\n",
              " [14, 5],\n",
              " [14, 5, 15],\n",
              " [14, 5, 15, 9],\n",
              " [14, 5, 15, 9, 5],\n",
              " [14, 5, 15, 9, 5, 4]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmUKVgMiEkVb"
      },
      "source": [
        "We also need to know what is the maximum length of our examples. So why do we want to know that? \r\n",
        "\r\n",
        "because we will not have a variable length input to our model. We will have a fixed length and one way to making these sequences before fit in the model, wich expects a fixed length is to simply put zeros, which does not really mean anything, it just means ignored.  So let's calculate the maximum length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjRTMysvpt2o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9d3bcb5-6a92-43dc-9f1c-8532e6da846b"
      },
      "source": [
        "max_len = max([len(x) for x in sequences])\r\n",
        "print(max_len)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGNy7IE8GqQl"
      },
      "source": [
        "So these sequences can be padded with zero. So all our sequences are going to be 33 of length. In the first example You can see all zeros an in the end we have 25 and 16, we use pedding pre because is more easier for us to create labels, all we have to do now is split each example in two, so the last character is always going to be the label and the sequences os number until that last character is goingo to be our example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR68pu2tpt2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32ac76e3-9702-423f-dff6-83c96a5fff32"
      },
      "source": [
        "padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(\r\n",
        "    sequences, \r\n",
        "    padding='pre',\r\n",
        "    maxlen=max_len\r\n",
        ")\r\n",
        "print(padded_sequences[0])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0 25 16]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_1BtWO7pt2r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eaf2764-9f03-4526-b044-5785a53fc3d5"
      },
      "source": [
        "padded_sequences.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88279, 33)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HXesty05zRt"
      },
      "source": [
        "## Task 5: Creating Training and Validation Sets\n",
        "\n",
        "1. Creating training and validation sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybUO4PEpaPZp"
      },
      "source": [
        "We have to split our data in examples and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE4BIeSnpt2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae0c67a9-94f8-4ade-f6f6-db0106f38ccc"
      },
      "source": [
        "x, y = padded_sequences[:,:-1], padded_sequences[:, -1] # all the values not including the last one, and just the last one value\r\n",
        "print(x.shape, y.shape)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(88279, 32) (88279,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRJ9LpE_hmeB"
      },
      "source": [
        "\r\n",
        "Let's use sklearn for create training and validation sets\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA3uLv3J5zRt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0874a9d-8dca-4209-ca12-fc33f2da4753"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y)\r\n",
        "\r\n",
        "print(x_train.shape, y_train.shape)\r\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(66209, 32) (66209,)\n",
            "(22070, 32) (22070,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwTmTcPdiBBy"
      },
      "source": [
        "Let's take a look at the size os the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgqRZtqnpt2x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b3cbf53-6290-4199-e0e8-385a987b6a98"
      },
      "source": [
        "num_chars = len(char_to_index.keys())+1 # we need to add 1 because we added a zero to ou vocabulary\r\n",
        "num_chars"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W50XOtKJ5zRt"
      },
      "source": [
        "## Task 6: Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ezaJHWF5zRt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4aa8d5e-d102-47f7-94ab-6e2c14682769"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Embedding, Conv1D,MaxPooling1D, LSTM\r\n",
        "from tensorflow.keras.layers import Bidirectional, Dense\r\n",
        "\r\n",
        "model = Sequential([\r\n",
        "                    Embedding(num_chars, 8, input_length=max_len-1),\r\n",
        "                    Conv1D(64, 5, strides=1, activation='tanh', padding='causal'),\r\n",
        "                    MaxPooling1D(2),\r\n",
        "                    LSTM(32),\r\n",
        "                    Dense(num_chars, activation='softmax')\r\n",
        "])\r\n",
        "model.compile(\r\n",
        "    loss='sparse_categorical_crossentropy',\r\n",
        "    optimizer='adam',\r\n",
        "    metrics=['accuracy']\r\n",
        ")\r\n",
        "model.summary()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 32, 8)             232       \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 32, 64)            2624      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1 (None, 16, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 32)                12416     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 29)                957       \n",
            "=================================================================\n",
            "Total params: 16,229\n",
            "Trainable params: 16,229\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6i1rdCG5zRt"
      },
      "source": [
        "## Task 7: Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSVZPgM-mZmN"
      },
      "source": [
        "The model that we have created is pretty small so it will be pretty fast to train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0Ssl4qupt22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76300763-9279-4953-c01f-af1af6a47d6c"
      },
      "source": [
        "h = model.fit(x_train, y_train,\r\n",
        "              validation_data=(x_test, y_test),\r\n",
        "              epochs=50, verbose=2,\r\n",
        "              callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)]\r\n",
        "              )"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "2070/2070 - 10s - loss: 2.7302 - accuracy: 0.1934 - val_loss: 2.5770 - val_accuracy: 0.2250\n",
            "Epoch 2/50\n",
            "2070/2070 - 10s - loss: 2.5240 - accuracy: 0.2411 - val_loss: 2.4953 - val_accuracy: 0.2512\n",
            "Epoch 3/50\n",
            "2070/2070 - 10s - loss: 2.4596 - accuracy: 0.2589 - val_loss: 2.4499 - val_accuracy: 0.2623\n",
            "Epoch 4/50\n",
            "2070/2070 - 10s - loss: 2.4164 - accuracy: 0.2696 - val_loss: 2.4130 - val_accuracy: 0.2729\n",
            "Epoch 5/50\n",
            "2070/2070 - 10s - loss: 2.3804 - accuracy: 0.2794 - val_loss: 2.3917 - val_accuracy: 0.2757\n",
            "Epoch 6/50\n",
            "2070/2070 - 10s - loss: 2.3495 - accuracy: 0.2893 - val_loss: 2.3614 - val_accuracy: 0.2879\n",
            "Epoch 7/50\n",
            "2070/2070 - 10s - loss: 2.3214 - accuracy: 0.2960 - val_loss: 2.3404 - val_accuracy: 0.2983\n",
            "Epoch 8/50\n",
            "2070/2070 - 10s - loss: 2.2967 - accuracy: 0.3059 - val_loss: 2.3277 - val_accuracy: 0.3023\n",
            "Epoch 9/50\n",
            "2070/2070 - 10s - loss: 2.2749 - accuracy: 0.3103 - val_loss: 2.3105 - val_accuracy: 0.3071\n",
            "Epoch 10/50\n",
            "2070/2070 - 10s - loss: 2.2540 - accuracy: 0.3168 - val_loss: 2.2943 - val_accuracy: 0.3088\n",
            "Epoch 11/50\n",
            "2070/2070 - 9s - loss: 2.2349 - accuracy: 0.3210 - val_loss: 2.2805 - val_accuracy: 0.3150\n",
            "Epoch 12/50\n",
            "2070/2070 - 10s - loss: 2.2164 - accuracy: 0.3263 - val_loss: 2.2723 - val_accuracy: 0.3168\n",
            "Epoch 13/50\n",
            "2070/2070 - 10s - loss: 2.1992 - accuracy: 0.3324 - val_loss: 2.2626 - val_accuracy: 0.3198\n",
            "Epoch 14/50\n",
            "2070/2070 - 10s - loss: 2.1845 - accuracy: 0.3373 - val_loss: 2.2551 - val_accuracy: 0.3253\n",
            "Epoch 15/50\n",
            "2070/2070 - 9s - loss: 2.1699 - accuracy: 0.3422 - val_loss: 2.2434 - val_accuracy: 0.3294\n",
            "Epoch 16/50\n",
            "2070/2070 - 10s - loss: 2.1556 - accuracy: 0.3460 - val_loss: 2.2408 - val_accuracy: 0.3314\n",
            "Epoch 17/50\n",
            "2070/2070 - 10s - loss: 2.1432 - accuracy: 0.3500 - val_loss: 2.2363 - val_accuracy: 0.3354\n",
            "Epoch 18/50\n",
            "2070/2070 - 11s - loss: 2.1310 - accuracy: 0.3542 - val_loss: 2.2350 - val_accuracy: 0.3360\n",
            "Epoch 19/50\n",
            "2070/2070 - 9s - loss: 2.1199 - accuracy: 0.3591 - val_loss: 2.2299 - val_accuracy: 0.3373\n",
            "Epoch 20/50\n",
            "2070/2070 - 10s - loss: 2.1095 - accuracy: 0.3628 - val_loss: 2.2274 - val_accuracy: 0.3355\n",
            "Epoch 21/50\n",
            "2070/2070 - 10s - loss: 2.0995 - accuracy: 0.3646 - val_loss: 2.2187 - val_accuracy: 0.3402\n",
            "Epoch 22/50\n",
            "2070/2070 - 9s - loss: 2.0905 - accuracy: 0.3675 - val_loss: 2.2161 - val_accuracy: 0.3438\n",
            "Epoch 23/50\n",
            "2070/2070 - 10s - loss: 2.0823 - accuracy: 0.3727 - val_loss: 2.2122 - val_accuracy: 0.3454\n",
            "Epoch 24/50\n",
            "2070/2070 - 10s - loss: 2.0739 - accuracy: 0.3737 - val_loss: 2.2076 - val_accuracy: 0.3479\n",
            "Epoch 25/50\n",
            "2070/2070 - 10s - loss: 2.0657 - accuracy: 0.3764 - val_loss: 2.2109 - val_accuracy: 0.3475\n",
            "Epoch 26/50\n",
            "2070/2070 - 10s - loss: 2.0578 - accuracy: 0.3798 - val_loss: 2.2048 - val_accuracy: 0.3539\n",
            "Epoch 27/50\n",
            "2070/2070 - 10s - loss: 2.0507 - accuracy: 0.3820 - val_loss: 2.2069 - val_accuracy: 0.3530\n",
            "Epoch 28/50\n",
            "2070/2070 - 10s - loss: 2.0447 - accuracy: 0.3842 - val_loss: 2.2050 - val_accuracy: 0.3524\n",
            "Epoch 29/50\n",
            "2070/2070 - 10s - loss: 2.0367 - accuracy: 0.3866 - val_loss: 2.2049 - val_accuracy: 0.3540\n",
            "Epoch 30/50\n",
            "2070/2070 - 10s - loss: 2.0307 - accuracy: 0.3898 - val_loss: 2.2092 - val_accuracy: 0.3543\n",
            "Epoch 31/50\n",
            "2070/2070 - 10s - loss: 2.0248 - accuracy: 0.3918 - val_loss: 2.2020 - val_accuracy: 0.3566\n",
            "Epoch 32/50\n",
            "2070/2070 - 10s - loss: 2.0186 - accuracy: 0.3939 - val_loss: 2.2048 - val_accuracy: 0.3525\n",
            "Epoch 33/50\n",
            "2070/2070 - 10s - loss: 2.0125 - accuracy: 0.3955 - val_loss: 2.1994 - val_accuracy: 0.3569\n",
            "Epoch 34/50\n",
            "2070/2070 - 10s - loss: 2.0067 - accuracy: 0.3969 - val_loss: 2.2028 - val_accuracy: 0.3574\n",
            "Epoch 35/50\n",
            "2070/2070 - 10s - loss: 2.0023 - accuracy: 0.3979 - val_loss: 2.1983 - val_accuracy: 0.3553\n",
            "Epoch 36/50\n",
            "2070/2070 - 10s - loss: 1.9970 - accuracy: 0.3997 - val_loss: 2.1963 - val_accuracy: 0.3547\n",
            "Epoch 37/50\n",
            "2070/2070 - 10s - loss: 1.9924 - accuracy: 0.4022 - val_loss: 2.1996 - val_accuracy: 0.3599\n",
            "Epoch 38/50\n",
            "2070/2070 - 9s - loss: 1.9888 - accuracy: 0.4043 - val_loss: 2.1954 - val_accuracy: 0.3602\n",
            "Epoch 39/50\n",
            "2070/2070 - 10s - loss: 1.9828 - accuracy: 0.4048 - val_loss: 2.2004 - val_accuracy: 0.3571\n",
            "Epoch 40/50\n",
            "2070/2070 - 10s - loss: 1.9797 - accuracy: 0.4057 - val_loss: 2.2012 - val_accuracy: 0.3580\n",
            "Epoch 41/50\n",
            "2070/2070 - 10s - loss: 1.9756 - accuracy: 0.4059 - val_loss: 2.2033 - val_accuracy: 0.3583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr1fVhFIp6CW"
      },
      "source": [
        "The training for me run for 41 epochs and i got 35% validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "5NnDFLSdqNLA",
        "outputId": "190aed9b-240c-4ccd-e653-440dcefc8b48"
      },
      "source": [
        "from matplotlib import  pyplot as plt\r\n",
        "\r\n",
        "epochs_ran = len(h.history['loss'])\r\n",
        "\r\n",
        "plt.plot(range(0, epochs_ran), h.history['val_accuracy'], label= 'Validation')\r\n",
        "plt.plot(range(0, epochs_ran), h.history['accuracy'], label= 'Training')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rHguRAf5zRu"
      },
      "source": [
        "## Task 8: Generate Names!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6PcozLvrIgP"
      },
      "source": [
        "seed could be a single character or a sequence of characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f50aTRcpt24"
      },
      "source": [
        "def generate_names(seed):\r\n",
        "    for i in range(0,40):\r\n",
        "      seq = name_to_seq(seed)\r\n",
        "      padded = tf.keras.preprocessing.sequence.pad_sequences([seq], \r\n",
        "                                                             padding='pre', \r\n",
        "                                                             maxlen=max_len-1,\r\n",
        "                                                             truncating='pre')\r\n",
        "      pred = model.predict(padded)[0]\r\n",
        "      pred_char = index_to_char[tf.argmax(pred).numpy()]\r\n",
        "      seed += pred_char\r\n",
        "\r\n",
        "      if pred_char == '\\t':\r\n",
        "        break\r\n",
        "    print(seed) "
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faQ0FInlpt26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71fec924-e206-4835-8932-dd7428995c14"
      },
      "source": [
        "generate_names('peter')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "peter mariu\t\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}